"""
Enhanced quality filters for GPU listings - Post-Processing Statistical Filtering

This module implements post-processing filtering:
1. SCRAPE: Collect ALL data without filtering
2. POST-PROCESS: Apply statistical outlier detection after scraping is complete

Advantages:
- No warm-up phase needed - we have full statistics before filtering
- More accurate outlier detection with complete dataset
- Easier to debug and tune thresholds
"""
from typing import Tuple, Optional, List, Dict, Any
import re
from core.logging import get_logger
from core.config import config

logger = get_logger("filters")

# Expanded blacklist keywords
BLACKLIST_KEYWORDS = [
    # Bulgarian
    "Ð·Ð°ÐµÐºÑ‚ÑƒÑ€Ð¸", "Ð·Ð° Ñ‡Ð°ÑÑ‚", "Ñ‡Ð°ÑÑ‚ Ð·Ð°", "Ñ‡Ð°ÑÑ‚Ð¸ Ð·Ð°", "ÑÑ‡ÑƒÐ¿ÐµÐ½Ð°", "Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð¸", "Ð¿Ð¾Ð²Ñ€ÐµÐ´ÐµÐ½Ð°", "Ð´ÐµÑ„ÐµÐºÑ‚",
    "Ð·Ð° Ñ€ÐµÐ¼Ð¾Ð½Ñ‚", "Ñ€ÐµÐ¼Ð¾Ð½Ñ‚ÐµÐ½", "Ñ€ÐµÐ¼Ð¾Ð½Ñ‚ÐµÐ½ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚", "ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚ Ð·Ð° Ñ€ÐµÐ¼Ð¾Ð½Ñ‚",
    "Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð¸", "Ñ‡ÐµÑ€ÐµÐ½ ÐµÐºÑ€Ð°Ð½", "Ð½Ðµ Ð´Ð°Ð²Ð° ÐµÐºÑ€Ð°Ð½", "Ð½Ðµ ÑÑ‚Ð°Ñ€Ñ‚Ð¸Ñ€Ð°", "Ð¸Ð·Ð³Ð¾Ñ€Ñ",
    "Ñ€Ð°Ð·Ð²Ð°Ð»ÐµÐ½", "Ð½ÐµÑ‚ÐµÑÑ‚Ð²Ð°Ð½Ð°", "Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼", "Ð½Ðµ Ðµ Ñ‚ÐµÑÑ‚Ð²Ð°Ð½Ð°", "Ð´ÐµÑ„ÐµÐºÑ‚Ð½Ð°", "Ð½Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð¸Ñ€Ð°", "Ð¸Ð·Ð¿Ñ€Ð°Ð²Ð½Ð¸",
    "Ð½ÑÐ¼Ð° ÑÐ¸Ð³Ð½Ð°Ð»", "Ð±ÐµÐ· ÑÐ¸Ð³Ð½Ð°Ð»", "Ð½Ðµ Ð´Ð°Ð²Ð° ÑÐ¸Ð³Ð½Ð°Ð»",

    # Parts only (not full cards)
    "Ð²ÐµÐ½Ñ‚Ð¸Ð»Ð°Ñ‚Ð¾Ñ€", "Ð²ÐµÐ½Ñ‚Ð¸Ð»Ð°Ñ‚Ð¾Ñ€Ð¸", "Ð¾Ñ…Ð»Ð°Ð¶Ð´Ð°Ð½Ðµ", "Ð¾Ñ…Ð»Ð°Ð´Ð¸Ñ‚ÐµÐ»", "Ð¼Ð¸ÑˆÐºÐ°", "backplate", "Ð±ÐµÐºÐ¿Ð»ÐµÐ¹Ñ‚",
    "Ñ€Ð°Ð´Ð¸Ð°Ñ‚Ð¾Ñ€", "heatsink", "thermal pad", "Ñ‚ÐµÑ€Ð¼Ð¾Ð¿Ð°Ð´", "Ñ‚ÐµÑ€Ð¼Ð¾Ð¿Ð°Ð´Ð¾Ð²Ðµ",
    "water block", "waterblock", "Ð²Ð¾Ð´ÐµÐ½ Ð±Ð»Ð¾Ðº", "Ð²Ð¾Ð´Ð½Ð¾ Ð¾Ñ…Ð»Ð°Ð¶Ð´Ð°Ð½Ðµ", "Ð²Ð¾Ð´Ð½Ð¾ Ð±Ð»Ð¾Ðº",
    "liquid cooling",

    # Mining-related (often worn out)
    "Ð¼Ð°Ð¹Ð½Ð¸Ð½Ð³", "mining", "burnout", "mining rig", "ÐºÐ¾Ð¿Ð°Ð½Ð°", "Ñ„ÐµÑ€Ð¼Ð°", "mining farm",
    "Ð¾Ñ‚ Ñ„ÐµÑ€Ð¼Ð°", "Ð¾Ñ‚ Ð¼Ð°Ð¹Ð½Ð¸Ð½Ð³", "Ð·Ð° Ð¼Ð°Ð¹Ð½Ð¸Ð½Ð³", "ÐºÐ¾Ð¿Ð°ÐµÐ½Ðµ",

    # English
    "broken", "damaged", "faulty", "defective", "not working", "for parts",
    "parts only", "part for", "for part", "as is", "repair", "artifacts", "black screen",
    "burnt", "dead", "fried", "doa", "no signal", "no display",
    "fan", "fans", "cooler", "cooling", "mouse",

    # Common suspicious patterns
    "ÑÑ€Ð¾Ñ‡Ð½Ð¾", "Ð±ÑŠÑ€Ð·Ð¾", "ÑÐ¿ÐµÑˆÐ½Ð¾",  # Often scams
]

# Keywords indicating full computer listings (not just GPU)
COMPUTER_KEYWORDS = [
    # Bulgarian
    "ÐºÐ¾Ð¼Ð¿ÑŽÑ‚ÑŠÑ€", "ÐºÐ¾Ð¼Ð¿ÑŽÑ‚Ñ€", "ÐºÐµÐ¹Ñ", "ÐºÑƒÑ‚Ð¸Ñ", "ÑÐ¸ÑÑ‚ÐµÐ¼Ð°", "ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ",
    "Ð³ÐµÐ¹Ð¼ÑŠÑ€ÑÐºÐ¸ Ð¿Ðº", "Ð¾Ñ„Ð¸ÑÐµÐ½ Ð¿Ðº", "Ð½Ð°ÑÑ‚Ð¾Ð»ÐµÐ½ ÐºÐ¾Ð¼Ð¿ÑŽÑ‚ÑŠÑ€", "Ð´ÐµÑÐºÑ‚Ð¾Ð¿",
    "Ð»Ð°Ð¿Ñ‚Ð¾Ð¿", "Ð¿Ñ€ÐµÐ½Ð¾ÑÐ¸Ð¼", "Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐº", "Ð½Ð¾Ñ‚Ð±ÑƒÐº",

    # English
    "desktop", "gaming pc", "office pc", "computer", "system", "build",
    "configuration", "full pc", "complete pc", "tower",
    "laptop", "notebook", "portable",

    # Multiple components (indicates full system)
    "i3 ", "i5 ", "i7 ", "i9 ", "ryzen 3", "ryzen 5", "ryzen 7", "ryzen 9",
    "+ cpu", "+ ram", "+ Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ñ€", "+ ssd", "+ hdd",
]

# Outlier detection thresholds
OUTLIER_THRESHOLD_LOW = 0.40   # 40% Ð¾Ñ‚ Ð¼ÐµÐ´Ð¸Ð°Ð½Ð°Ñ‚Ð° (Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð°Ð½Ð¾ Ñ„Ð¸Ð»Ñ‚Ñ€Ð¸Ñ€Ð°Ð½Ðµ Ð½Ð° Ñ‚Ð²ÑŠÑ€Ð´Ðµ Ð½Ð¸ÑÐºÐ¸ Ñ†ÐµÐ½Ð¸)
OUTLIER_THRESHOLD_HIGH = 3.0   # 300% Ð¾Ñ‚ Ð¼ÐµÐ´Ð¸Ð°Ð½Ð°Ñ‚Ð° (DISABLED - Ð½Ðµ ÑÐµ Ð¸Ð·Ð¿Ð¾Ð»Ð·Ð²Ð°)

# Minimum sample size Ð·Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
MIN_SAMPLE_SIZE = 3  # ÐœÐ¸Ð½Ð¸Ð¼ÑƒÐ¼ 3 Ð¾Ð±ÑÐ²Ð¸ Ð·Ð° Ð´Ð° Ð¿Ñ€Ð¸Ð»Ð¾Ð¶Ð¸Ð¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° (Ð‘Ð•Ð— warm-up Ñ„Ð°Ð·Ð°)
ADAPTIVE_WARMUP_SIZE = 5  # Ð¡Ð»ÐµÐ´ 5 Ð¾Ð±ÑÐ²Ð¸ Ð¸Ð·Ð¿Ð¾Ð»Ð·Ð²Ð°Ð¼Ðµ Ð¿ÑŠÐ»Ð½Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ° Ñ„Ð¸Ð»Ñ‚Ñ€Ð°Ñ†Ð¸Ñ


# Model corrections for incomplete/ambiguous names and non-existent variants
MODEL_CORRECTIONS = {
    # AMD RX 7000-series - fix incomplete model names
    "RX 7900": "RX 7900 XT",      # Default to XT (most common)
    "RX 7800": "RX 7800 XT",      # Only XT variant exists
    "RX 7700": "RX 7700 XT",      # Only XT variant exists
    "RX 7600": "RX 7600",         # Non-XT is the base model

    # AMD RX 6000-series - fix incomplete model names
    "RX 6950": "RX 6950 XT",      # Only XT variant exists
    "RX 6900": "RX 6900 XT",      # Only XT variant exists
    "RX 6800": "RX 6800",         # Non-XT is valid
    "RX 6700": "RX 6700 XT",      # XT is more common
    "RX 6600": "RX 6600",         # Non-XT is the base model
    "RX 6500": "RX 6500 XT",      # Only XT variant exists

    # AMD RX 5000-series
    "RX 5700": "RX 5700 XT",      # XT is more common
    "RX 5600": "RX 5600 XT",      # Only XT variant exists
    "RX 5500": "RX 5500 XT",      # Only XT variant exists

    # NVIDIA RTX 40-series - removed auto-corrections to allow precise VRAM matching
    # Now with VRAM extraction, we want to keep exact model names

    # NVIDIA RTX 30-series - removed auto-corrections to allow precise VRAM matching
    # "RTX 3060" and "RTX 3060 TI" are different cards

    # NVIDIA RTX 20-series
    "RTX 2080": "RTX 2080 SUPER", # SUPER is more common
    "RTX 2070": "RTX 2070 SUPER", # SUPER is more common
    "RTX 2060": "RTX 2060 SUPER", # SUPER is more common

    # Common typos and errors
    "GTX 1060 SUPER": "GTX 1660 SUPER",  # Common confusion
    "GTX 1600": "GTX 1650 SUPER",        # Typo
    "RTX 2260 SUPER": "RTX 2060 SUPER",  # Typo
    "RX 1650": "GTX 1650 SUPER",         # Brand confusion (AMD â†’ NVIDIA)

    # ===================================================================
    # Non-existent GPU models - normalize to real equivalents
    # These variants were never released but sellers often list them incorrectly
    # ===================================================================

    # NVIDIA GTX 10-series - no SUPER variants exist (SUPER only in GTX 16-series)
    "GTX 1080 SUPER": "GTX 1080",    # GTX 1080 SUPER doesn't exist â†’ GTX 1080
    "GTX 1070 SUPER": "GTX 1070",    # GTX 1070 SUPER doesn't exist â†’ GTX 1070
    "GTX 1060 3GB SUPER": "GTX 1060 3GB",  # No SUPER variant
    "GTX 1060 6GB SUPER": "GTX 1060 6GB",  # No SUPER variant
    "GTX 1050 SUPER": "GTX 1050",    # GTX 1050 SUPER doesn't exist â†’ GTX 1050

    # NVIDIA RTX 30-series - no SUPER variants (SUPER only in 20-series and 40-series)
    "RTX 3090 SUPER": "RTX 3090",
    "RTX 3090 TI SUPER": "RTX 3090 TI",
    "RTX 3080 SUPER": "RTX 3080",
    "RTX 3080 TI SUPER": "RTX 3080 TI",
    "RTX 3080 12GB SUPER": "RTX 3080 12GB",
    "RTX 3070 SUPER": "RTX 3070",
    "RTX 3070 TI SUPER": "RTX 3070 TI",
    "RTX 3060 SUPER": "RTX 3060",
    "RTX 3060 TI SUPER": "RTX 3060 TI",
    "RTX 3060 12GB SUPER": "RTX 3060 12GB",
    "RTX 3050 SUPER": "RTX 3050",
    "RTX 3050 8GB SUPER": "RTX 3050 8GB",

    # NVIDIA RTX 20-series - only 2060/2070/2080 have SUPER variants
    "RTX 2080 TI SUPER": "RTX 2080 TI",  # RTX 2080 TI exists, but no SUPER variant
    "RTX 2090": "RTX 2080 TI",           # RTX 2090 doesn't exist, likely means 2080 TI
    "RTX 2090 SUPER": "RTX 2080 TI",
    "RTX 2090 TI": "RTX 2080 TI",
    "RTX 2050": "RTX 2060",              # RTX 2050 doesn't exist, likely means 2060
    "RTX 2050 SUPER": "RTX 2060 SUPER",

    # NVIDIA RTX 40-series - limited SUPER variants
    "RTX 4090 SUPER": "RTX 4090",        # RTX 4090 doesn't have SUPER variant
    "RTX 4090 TI": "RTX 4090",           # RTX 4090 TI doesn't exist
    "RTX 4060 SUPER": "RTX 4060",        # Only RTX 4060 TI exists, not 4060 SUPER

    # NVIDIA GTX 16-series - only 1650 and 1660 have SUPER
    "GTX 1630 SUPER": "GTX 1650 SUPER",  # Likely confusion
    "GTX 1640 SUPER": "GTX 1650 SUPER",  # Likely confusion

    # AMD RX cards - no SUPER variants (AMD uses XT/XTX nomenclature)
    "RX 7900 SUPER": "RX 7900 XT",
    "RX 7800 SUPER": "RX 7800 XT",
    "RX 7700 SUPER": "RX 7700 XT",
    "RX 7600 SUPER": "RX 7600",
    "RX 6900 SUPER": "RX 6900 XT",
    "RX 6800 SUPER": "RX 6800 XT",
    "RX 6700 SUPER": "RX 6700 XT",
    "RX 6600 SUPER": "RX 6600 XT",
    "RX 5700 SUPER": "RX 5700 XT",
    "RX 5600 SUPER": "RX 5600 XT",
}


def normalize_model_name(model: str) -> str:
    """
    Normalize GPU model name for consistency

    Examples:
        RTX3060TI -> RTX 3060 TI
        RTX 3060TI -> RTX 3060 TI
        RX6600XT -> RX 6600 XT
        VEGA56 -> VEGA 56
        gtx 1660ti -> GTX 1660 TI
        GTX 1060 6GB -> GTX 1060 6GB
        RX 7900 -> RX 7900 XT (autocorrect incomplete names)
        AMD Radeon RX 7900 GRE -> RX 7900 GRE
    """
    if not model:
        return model

    # Convert to uppercase
    model = model.upper().strip()

    # Remove brand prefixes (AMD, NVIDIA, GEFORCE, RADEON, INTEL) - with optional spaces
    # This must run BEFORE removing all spaces
    model = re.sub(r'^(AMD|NVIDIA|GEFORCE|RADEON|INTEL)\s+', '', model)

    # Remove "RADEON" if it appears after removing first prefix (e.g., "AMD RADEON RX")
    model = re.sub(r'^RADEON\s+', '', model)
    model = re.sub(r'^GEFORCE\s+', '', model)

    # Remove all remaining spaces
    model = model.replace(" ", "")

    # Add space after brand (RTX, GTX, RX, VEGA, ARC)
    model = re.sub(r'(RTX|GTX|RX|VEGA|ARC)(\d+)', r'\1 \2', model)

    # Special handling for Intel ARC (format: ARC A750, ARC B580)
    model = re.sub(r'ARC([AB])(\d{3})', r'ARC \1\2', model)

    # Add space before memory size (3GB, 6GB, 8GB, 12GB, 16GB, etc.) - FIRST
    # This must run before TI/SUPER/XT to handle cases like "TI16GB"
    model = re.sub(r'(\d{4})(\d{1,2}GB)$', r'\1 \2', model)  # e.g., 30603GB -> 3060 3GB
    model = re.sub(r'(\d{3})(\d{1,2}GB)$', r'\1 \2', model)  # e.g., 5808GB -> 580 8GB (AMD RX 580, RX 570, etc.)
    model = re.sub(r'([AB]\d{3})(\d{1,2}GB)$', r'\1 \2', model)  # e.g., A77016GB -> A770 16GB (Intel ARC)
    model = re.sub(r'(TI|SUPER|XT|XTX|GRE)(\d{1,2}GB)$', r'\1 \2', model)  # e.g., TI16GB -> TI 16GB

    # Add space before suffix (TI, SUPER, XT, XTX, GRE)
    model = re.sub(r'(\d+)(TI|SUPER|XT|XTX|GRE)', r'\1 \2', model)

    # Apply model corrections for incomplete/ambiguous names
    if model in MODEL_CORRECTIONS:
        corrected = MODEL_CORRECTIONS[model]
        logger.debug(f"Model correction: '{model}' â†’ '{corrected}'")
        model = corrected

    return model


def is_suspicious_listing(
    title: str,
    price: float,
    gpu_model: str,
    dynamic_min_price: int = 0,
    all_prices_for_model: Optional[List[float]] = None
) -> Tuple[bool, str]:
    """
    DEPRECATED: This function is no longer used for real-time filtering.

    Filtering now happens in post-processing via filter_scraped_data().
    This function is kept for backwards compatibility only.

    Args:
        title: Listing title
        price: Price in BGN
        gpu_model: GPU model name
        dynamic_min_price: Deprecated (kept for backwards compatibility)
        all_prices_for_model: Deprecated (kept for backwards compatibility)

    Returns:
        Tuple of (is_suspicious: bool, reason: str)
    """
    title_lower = title.lower()

    # Normalize the model for comparison
    gpu_model = normalize_model_name(gpu_model)

    # 1. Check for blacklisted keywords (ALWAYS APPLIED - HIGHEST PRIORITY)
    for keyword in BLACKLIST_KEYWORDS:
        if keyword.lower() in title_lower:
            return (True, f"Contains blacklisted keyword: '{keyword}'")

    # 2. Check for computer/full system listings (ALWAYS APPLIED)
    for keyword in COMPUTER_KEYWORDS:
        if keyword.lower() in title_lower:
            return (True, f"Full computer listing (not just GPU): '{keyword}'")

    # 3. Extremely low price check (ALWAYS APPLIED - universal red flag)
    if price < 50:
        return (True, f"Extremely low price: {price}Ð»Ð² (likely broken)")

    # 3. Title length check (ALWAYS APPLIED - low quality listings)
    if len(title) < 10:
        return (True, f"Title too short: '{title}'")

    # 4. ADAPTIVE Statistical outlier detection
    # Only apply if we have enough samples (warm-up phase complete)
    if all_prices_for_model and len(all_prices_for_model) >= ADAPTIVE_WARMUP_SIZE:
        import statistics

        median = statistics.median(all_prices_for_model)

        # Check if price is too low (outlier)
        low_threshold = median * OUTLIER_THRESHOLD_LOW
        if price < low_threshold:
            return (
                True,
                f"Statistical outlier: {price}Ð»Ð² < {low_threshold:.0f}Ð»Ð² "
                f"(30% of median {median:.0f}Ð»Ð²)"
            )

        # Check if price is too high (probably scam/wrong listing)
        high_threshold = median * OUTLIER_THRESHOLD_HIGH
        if price > high_threshold:
            return (
                True,
                f"Price too high: {price}Ð»Ð² > {high_threshold:.0f}Ð»Ð² "
                f"(300% of median {median:.0f}Ð»Ð²)"
            )

    # All checks passed
    return (False, "OK")


def calculate_statistics(prices: List[float]) -> Optional[Dict[str, Any]]:
    """
    Calculate statistics for a list of prices
    
    Args:
        prices: List of prices
    
    Returns:
        Dict with median, mean, std_dev, q1, q3, iqr
        None if not enough data
    """
    if not prices or len(prices) < 2:
        return None
    
    import statistics
    
    sorted_prices = sorted(prices)
    n = len(sorted_prices)
    
    stats = {
        'median': statistics.median(sorted_prices),
        'mean': statistics.mean(sorted_prices),
        'count': n,
    }
    
    # Standard deviation (if enough data)
    if n >= 2:
        stats['std_dev'] = statistics.stdev(sorted_prices)
    
    # Quartiles (if enough data)
    if n >= 4:
        stats['q1'] = sorted_prices[n // 4]
        stats['q3'] = sorted_prices[3 * n // 4]
        stats['iqr'] = stats['q3'] - stats['q1']
    
    return stats


def filter_scraped_data(raw_data: Dict[str, List]) -> tuple[Dict[str, List], Dict[str, int], List[Dict]]:
    """
    Post-processing filtering: Ñ„Ð¸Ð»Ñ‚Ñ€Ð¸Ñ€Ð° scraped Ð´Ð°Ð½Ð½Ð¸ Ð¡Ð›Ð•Ð” ÑÑŠÐ±Ð¸Ñ€Ð°Ð½ÐµÑ‚Ð¾ Ð¸Ð¼

    ÐŸÑ€ÐµÐ´Ð¸Ð¼ÑÑ‚Ð²Ð°:
    - Ð˜Ð¼Ð°Ð¼Ðµ Ð¿ÑŠÐ»Ð½Ð°Ñ‚Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€ÐµÐ´Ð¸ Ñ„Ð¸Ð»Ñ‚Ñ€Ð¸Ñ€Ð°Ð½Ðµ (Ð½ÑÐ¼Ð° warm-up Ñ„Ð°Ð·Ð°)
    - ÐŸÐ¾-Ñ‚Ð¾Ñ‡Ð½Ð¾ outlier detection
    - ÐŸÐ¾-Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð·Ð° debugging

    Args:
        raw_data: Ð ÐµÑ‡Ð½Ð¸Ðº {model: [items]} ÐºÑŠÐ´ÐµÑ‚Ð¾ items ÑÐ° dict{'price': float, 'url': str, 'title': str}

    Returns:
        Tuple of (filtered_data, filter_stats, rejected_listings)
        - filtered_data: Ð ÐµÑ‡Ð½Ð¸Ðº {model: [items]} ÑÐ°Ð¼Ð¾ Ñ Ð²Ð°Ð»Ð¸Ð´Ð½Ð¸ listings
        - filter_stats: Ð ÐµÑ‡Ð½Ð¸Ðº {reason: count} Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð·Ð° Ñ„Ð¸Ð»Ñ‚Ñ€Ð¸Ñ€Ð°Ð½Ðµ
        - rejected_listings: List of rejected items with reasons
    """
    filtered_data = {}
    rejected_listings = []  # Track all rejected listings
    filter_stats = {
        'blacklist_keywords': 0,
        'full_computer': 0,
        'extremely_low_price': 0,
        'statistical_outlier_low': 0,
        'statistical_outlier_high': 0,
        'total_filtered': 0,
        'total_kept': 0,
    }

    for model, items in raw_data.items():
        if not items:
            continue

        valid_items = []
        for item in items:
            price = item['price']
            title = item.get('title', '')
            title_lower = title.lower()
            url = item.get('url', '')

            # Check for blacklisted keywords (highest priority - broken/defective GPUs)
            blacklisted = False
            for keyword in BLACKLIST_KEYWORDS:
                if keyword.lower() in title_lower:
                    filter_stats['blacklist_keywords'] += 1
                    filter_stats['total_filtered'] += 1
                    reason = f"Blacklisted keyword: '{keyword}'"
                    rejected_listings.append({
                        'title': title,
                        'price': price,
                        'url': url,
                        'model': model,
                        'reason': reason,
                        'category': 'ðŸš« Blacklisted Keywords'
                    })
                    logger.debug(f"Filtered {model} @ {price}Ð»Ð²: {reason}")
                    blacklisted = True
                    break
            if blacklisted:
                continue

            # Check for full computer listings (not just GPU)
            is_computer = False
            for keyword in COMPUTER_KEYWORDS:
                if keyword.lower() in title_lower:
                    filter_stats['full_computer'] += 1
                    filter_stats['total_filtered'] += 1
                    reason = f"Full computer listing: '{keyword}'"
                    rejected_listings.append({
                        'title': title,
                        'price': price,
                        'url': url,
                        'model': model,
                        'reason': reason,
                        'category': 'ðŸ’» Full Computer/Laptop'
                    })
                    logger.debug(f"Filtered {model} @ {price}Ð»Ð²: {reason}")
                    is_computer = True
                    break
            if is_computer:
                continue

            # Statistical outlier detection - only for low prices
            # We need to collect all prices first, then filter
            valid_items.append(item)

        # Now apply statistical filtering if we have enough samples
        if valid_items and len(valid_items) >= MIN_SAMPLE_SIZE:
            import statistics

            prices = [item['price'] for item in valid_items]
            median = statistics.median(prices)
            low_threshold = median * OUTLIER_THRESHOLD_LOW

            # Filter out low price outliers
            final_items = []
            for item in valid_items:
                price = item['price']
                if price < low_threshold:
                    filter_stats['statistical_outlier_low'] += 1
                    filter_stats['total_filtered'] += 1
                    reason = f"Too low: {price:.0f}Ð»Ð² < {low_threshold:.0f}Ð»Ð² (40% of median {median:.0f}Ð»Ð²)"
                    rejected_listings.append({
                        'title': item.get('title', ''),
                        'price': price,
                        'url': item.get('url', ''),
                        'model': model,
                        'reason': reason,
                        'category': 'ðŸ“‰ Statistical Outlier (Low Price)'
                    })
                    logger.debug(f"Filtered {model} @ {price}Ð»Ð²: {reason}")
                else:
                    final_items.append(item)
                    filter_stats['total_kept'] += 1

            if final_items:
                filtered_data[model] = final_items
        elif valid_items:
            # Not enough samples for statistics, keep all
            for item in valid_items:
                filter_stats['total_kept'] += 1
            filtered_data[model] = valid_items

    return filtered_data, filter_stats, rejected_listings


def get_filter_summary(filtered_data: Dict[str, List[float]]) -> str:
    """
    Generate a summary of post-processing filtering results

    Args:
        filtered_data: Dict of {model: [prices]} AFTER filtering

    Returns:
        Formatted string with filtering info
    """
    summary = []
    summary.append("ðŸ“Š Post-Processing Filter Results:")
    summary.append(f"  Low Outlier Threshold:  < {OUTLIER_THRESHOLD_LOW * 100:.0f}% of median")
    summary.append(f"  Min Sample Size:        {MIN_SAMPLE_SIZE} listings")
    summary.append("")

    for model, prices in sorted(filtered_data.items()):
        if len(prices) >= MIN_SAMPLE_SIZE:
            import statistics
            median = statistics.median(prices)
            low = median * OUTLIER_THRESHOLD_LOW
            summary.append(
                f"  {model:20} â†’ min: {low:>5.0f}Ð»Ð² "
                f"(median: {median:.0f}Ð»Ð², n={len(prices)})"
            )
        else:
            summary.append(
                f"  {model:20} â†’ No filtering (n={len(prices)} < {MIN_SAMPLE_SIZE})"
            )

    return "\n".join(summary)